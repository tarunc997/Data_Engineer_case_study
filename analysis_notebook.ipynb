{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col, row_number,sum,desc\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is the expected output for the analytical questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# File location and type\n",
    "file_location = \"temp_dir/Data/Units_use.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df_units = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", True) \\\n",
    "  .option(\"header\", True) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"temp_dir/Data/Charges_use.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df_charges = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", True) \\\n",
    "  .option(\"header\", True) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"temp_dir/Data/Damages_use.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df_damages = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", True) \\\n",
    "  .option(\"header\", True) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# File location and type\n",
    "file_location = \"temp_dir/Data/Primary_Person_use.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df_primary = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", True) \\\n",
    "  .option(\"header\", True) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+---+\n",
      "|PRSN_INJRY_SEV_ID|PRSN_GNDR_ID|cnt|\n",
      "+-----------------+------------+---+\n",
      "|           KILLED|        MALE|182|\n",
      "+-----------------+------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#analysis-1\n",
    "conditions = (df_primary['PRSN_INJRY_SEV_ID'] == 'KILLED') & (df_primary['PRSN_GNDR_ID'] == 'MALE')\n",
    "result = df_primary.filter(conditions) \\\n",
    "            .groupBy(['PRSN_INJRY_SEV_ID','PRSN_GNDR_ID']) \\\n",
    "            .agg(count('*').alias('cnt')) \\\n",
    "                .filter('cnt > 2')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|summary|CRASH_ID|\n",
      "+-------+--------+\n",
      "|  count|     784|\n",
      "+-------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Analysis-2\n",
    "motorcycle_count = df_units.filter(col(\"VEH_BODY_STYL_ID\").contains(\"MOTORCYCLE\"))\n",
    "motorcycle_count.select('CRASH_ID').summary().limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| VEH_MAKE_ID|count|\n",
      "+------------+-----+\n",
      "|   CHEVROLET|   17|\n",
      "|        FORD|   12|\n",
      "|       DODGE|    7|\n",
      "|FREIGHTLINER|    6|\n",
      "|      NISSAN|    5|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Analysis 3 \n",
    "joined=df_primary.join(df_units,df_units.CRASH_ID==df_primary.CRASH_ID)\n",
    "conditions = (df_primary['PRSN_INJRY_SEV_ID'] == 'KILLED') & (df_primary['PRSN_AIRBAG_ID']=='NOT DEPLOYED') & (df_units['VEH_MAKE_ID'] !='NA')\n",
    "filtered_2=joined.filter(conditions).groupBy('VEH_MAKE_ID').agg(count(\"*\").alias(\"count\")).orderBy(desc(count('*'))).limit(5)\n",
    "filtered_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6359"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analysis 4: \n",
    "df = (\n",
    "            df_units.select(\"CRASH_ID\", \"VEH_HNR_FL\")\n",
    "            .join(\n",
    "                df_primary.select(\"CRASH_ID\", \"DRVR_LIC_TYPE_ID\"),\n",
    "                on=[\"CRASH_ID\"],\n",
    "                how=\"inner\"\n",
    "            )\n",
    "            .filter(\n",
    "                (col(\"VEH_HNR_FL\") == \"Y\")\n",
    "                & (\n",
    "                    col(\"DRVR_LIC_TYPE_ID\").isin(\n",
    "                        [\"DRIVER LICENSE\", \"COMMERCIAL DRIVER LIC.\"]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+\n",
      "|DRVR_LIC_STATE_ID|total_accidents|\n",
      "+-----------------+---------------+\n",
      "|            Texas|          83016|\n",
      "+-----------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#analysis 5 \n",
    "analysis_5 = df_primary.filter(df_primary['PRSN_GNDR_ID'] != 'FEMALE') \\\n",
    "                      .groupBy('DRVR_LIC_STATE_ID') \\\n",
    "                      .agg(count('*').alias('total_accidents')) \\\n",
    "                      .orderBy(desc(col('total_accidents'))) \\\n",
    "                      .limit(1)\n",
    "analysis_5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/01 17:38:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/01 17:38:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/01 17:38:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/01 17:38:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/01 17:38:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/06/01 17:38:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|VEH_MAKE_ID|total_injuries|\n",
      "+-----------+--------------+\n",
      "|     TOYOTA|          4228|\n",
      "|      DODGE|          3146|\n",
      "|     NISSAN|          3118|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#analysis 6 \n",
    "windowSpec = Window.orderBy(col(\"total_injuries\").desc())\n",
    "# Perform the analysis\n",
    "analysis_6 = df_units.groupBy(\"VEH_MAKE_ID\") \\\n",
    "                   .agg(sum(col(\"TOT_INJRY_CNT\") + col(\"DEATH_CNT\")).alias(\"total_injuries\")) \\\n",
    "                   .select(\"VEH_MAKE_ID\", \"total_injuries\", row_number().over(windowSpec).alias(\"row_number\"))\n",
    "# Filter rows where row number falls within the range of 3 to 5\n",
    "result_6 = analysis_6.filter((col(\"row_number\") >= 3) & (col(\"row_number\") <= 5)).drop(\"row_number\")\n",
    "result_6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:==========================================================(8 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----------------+---------------+\n",
      "|VEH_BODY_STYL_ID                 |PRSN_ETHNICITY_ID|ethnicity_count|\n",
      "+---------------------------------+-----------------+---------------+\n",
      "|AMBULANCE                        |WHITE            |97             |\n",
      "|BUS                              |HISPANIC         |391            |\n",
      "|FARM EQUIPMENT                   |WHITE            |63             |\n",
      "|FIRE TRUCK                       |WHITE            |112            |\n",
      "|MOTORCYCLE                       |WHITE            |848            |\n",
      "|NA                               |WHITE            |5693           |\n",
      "|NEV-NEIGHBORHOOD ELECTRIC VEHICLE|WHITE            |10             |\n",
      "|NOT REPORTED                     |HISPANIC         |2              |\n",
      "|OTHER  (EXPLAIN IN NARRATIVE)    |WHITE            |459            |\n",
      "|PASSENGER CAR, 2-DOOR            |WHITE            |9877           |\n",
      "|PASSENGER CAR, 4-DOOR            |WHITE            |58312          |\n",
      "|PICKUP                           |WHITE            |38609          |\n",
      "|POLICE CAR/TRUCK                 |WHITE            |366            |\n",
      "|POLICE MOTORCYCLE                |HISPANIC         |3              |\n",
      "|SPORT UTILITY VEHICLE            |WHITE            |33902          |\n",
      "|TRUCK                            |WHITE            |4204           |\n",
      "|TRUCK TRACTOR                    |WHITE            |5815           |\n",
      "|UNKNOWN                          |WHITE            |1178           |\n",
      "|VAN                              |WHITE            |5291           |\n",
      "|YELLOW SCHOOL BUS                |WHITE            |264            |\n",
      "+---------------------------------+-----------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "grouped_df = joined.groupBy('VEH_BODY_STYL_ID', 'PRSN_ETHNICITY_ID') \\\n",
    "    .agg(count('*').alias('ethnicity_count'))\n",
    "\n",
    "# Find the top ethnicity for each body style\n",
    "window_spec = Window.partitionBy('VEH_BODY_STYL_ID').orderBy(desc('ethnicity_count'))\n",
    "top_ethnicity_df = grouped_df.withColumn('rank', row_number().over(window_spec)) \\\n",
    "    .filter(col('rank') == 1) \\\n",
    "    .select('VEH_BODY_STYL_ID', 'PRSN_ETHNICITY_ID', 'ethnicity_count') \\\n",
    "    .orderBy('VEH_BODY_STYL_ID')\n",
    "\n",
    "# Display the results\n",
    "top_ethnicity_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|DRVR_ZIP|count|\n",
      "+--------+-----+\n",
      "|   76010|   75|\n",
      "|   78521|   61|\n",
      "|   75067|   54|\n",
      "|   78574|   47|\n",
      "|   75052|   43|\n",
      "+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "#analysis 8 \n",
    "df = (\n",
    "    df_units.join(df_primary, on=[\"CRASH_ID\"], how=\"inner\")\n",
    "    .dropna(subset=[\"DRVR_ZIP\"])\n",
    "    .filter(\n",
    "        col(\"CONTRIB_FACTR_1_ID\").contains(\"ALCOHOL\")\n",
    "        | col(\"CONTRIB_FACTR_2_ID\").contains(\"ALCOHOL\")\n",
    "    )\n",
    "    .groupby(\"DRVR_ZIP\")\n",
    "    .count()\n",
    "    .orderBy(col(\"count\").desc())\n",
    "    .limit(5)\n",
    ")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14870169, 14894076, 14996273, 15232090, 15232090, 15249931, 15307513]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (\n",
    "    df_damages.join(df_units, on=[\"CRASH_ID\"], how=\"inner\")\n",
    "    .filter(\n",
    "        (\n",
    "            (df_units.VEH_DMAG_SCL_1_ID > \"DAMAGED 4\")\n",
    "            & (\n",
    "                ~df_units.VEH_DMAG_SCL_1_ID.isin(\n",
    "                    [\"NA\", \"NO DAMAGE\", \"INVALID VALUE\"]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        | (\n",
    "            (df_units.VEH_DMAG_SCL_2_ID > \"DAMAGED 4\")\n",
    "            & (\n",
    "                ~df_units.VEH_DMAG_SCL_2_ID.isin(\n",
    "                    [\"NA\", \"NO DAMAGE\", \"INVALID VALUE\"]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .filter(df_damages.DAMAGED_PROPERTY == \"NONE\")\n",
    "    .filter(df_units.FIN_RESP_TYPE_ID == \"PROOF OF LIABILITY INSURANCE\")\n",
    ")\n",
    "\n",
    "[row[0] for row in df.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['FORD', 'CHEVROLET', 'TOYOTA', 'DODGE', 'NISSAN']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_25_state_list = [\n",
    "row[0]\n",
    "for row in df_units.filter(\n",
    "    col(\"VEH_LIC_STATE_ID\").cast(\"int\").isNull()\n",
    ")\n",
    ".groupby(\"VEH_LIC_STATE_ID\")\n",
    ".count()\n",
    ".orderBy(col(\"count\").desc())\n",
    ".limit(25)\n",
    ".collect()\n",
    "]\n",
    "top_10_used_vehicle_colors = [\n",
    "row[0]\n",
    "for row in df_units.filter(df_units.VEH_COLOR_ID != \"NA\")\n",
    ".groupby(\"VEH_COLOR_ID\")\n",
    ".count()\n",
    ".orderBy(col(\"count\").desc())\n",
    ".limit(10)\n",
    ".collect()\n",
    "]\n",
    "\n",
    "df = (\n",
    "df_charges.join(df_primary, on=[\"CRASH_ID\"], how=\"inner\")\n",
    ".join(df_units, on=[\"CRASH_ID\"], how=\"inner\")\n",
    ".filter(df_charges.CHARGE.contains(\"SPEED\"))\n",
    ".filter(\n",
    "    df_primary.DRVR_LIC_TYPE_ID.isin(\n",
    "        [\"DRIVER LICENSE\", \"COMMERCIAL DRIVER LIC.\"]\n",
    "    )\n",
    ")\n",
    ".filter(df_units.VEH_COLOR_ID.isin(top_10_used_vehicle_colors))\n",
    ".filter(df_units.VEH_LIC_STATE_ID.isin(top_25_state_list))\n",
    ".groupby(\"VEH_MAKE_ID\")\n",
    ".count()\n",
    ".orderBy(col(\"count\").desc())\n",
    ".limit(5)\n",
    ")\n",
    "\n",
    "[row[0] for row in df.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
